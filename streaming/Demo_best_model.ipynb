{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e212eca1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for JointModel:\n\tsize mismatch for trigger_classifier.4.weight: copying a param with shape torch.Size([21, 384]) from checkpoint, the shape in current model is torch.Size([20, 384]).\n\tsize mismatch for trigger_classifier.4.bias: copying a param with shape torch.Size([21]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for arg_classifier.4.weight: copying a param with shape torch.Size([8, 384]) from checkpoint, the shape in current model is torch.Size([20, 384]).\n\tsize mismatch for arg_classifier.4.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for event_classifier.4.weight: copying a param with shape torch.Size([13, 384]) from checkpoint, the shape in current model is torch.Size([10, 384]).\n\tsize mismatch for event_classifier.4.bias: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([10]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m encoder_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moneie_encoders\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     51\u001b[0m model \u001b[38;5;241m=\u001b[39m JointModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxlm-roberta-base\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(encoder_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger_encoder.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2593\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2585\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2586\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2587\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2588\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2589\u001b[0m             ),\n\u001b[0;32m   2590\u001b[0m         )\n\u001b[0;32m   2592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2594\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2595\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2596\u001b[0m         )\n\u001b[0;32m   2597\u001b[0m     )\n\u001b[0;32m   2598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for JointModel:\n\tsize mismatch for trigger_classifier.4.weight: copying a param with shape torch.Size([21, 384]) from checkpoint, the shape in current model is torch.Size([20, 384]).\n\tsize mismatch for trigger_classifier.4.bias: copying a param with shape torch.Size([21]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for arg_classifier.4.weight: copying a param with shape torch.Size([8, 384]) from checkpoint, the shape in current model is torch.Size([20, 384]).\n\tsize mismatch for arg_classifier.4.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for event_classifier.4.weight: copying a param with shape torch.Size([13, 384]) from checkpoint, the shape in current model is torch.Size([10, 384]).\n\tsize mismatch for event_classifier.4.bias: copying a param with shape torch.Size([13]) from checkpoint, the shape in current model is torch.Size([10])."
     ]
    }
   ],
   "source": [
    "from model import JointModel\n",
    "from transformers import XLMRobertaTokenizerFast\n",
    "import torch, pickle, os\n",
    "\n",
    "import torch\n",
    "\n",
    "def predict_single_instance(model, tokenizer, sentence_tokens, dataset_encoders, max_length=128):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    encoding = tokenizer(sentence_tokens, is_split_into_words=True, return_tensors='pt',\n",
    "                         padding='max_length', truncation=True, max_length=max_length)\n",
    "    word_ids = encoding.word_ids()\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        trigger_logits, arg_logits, event_logits = model(input_ids, attention_mask)\n",
    "        trigger_preds = torch.argmax(trigger_logits, dim=-1).cpu().numpy()[0]\n",
    "        arg_preds = torch.argmax(arg_logits, dim=-1).cpu().numpy()[0]\n",
    "        event_pred = torch.argmax(event_logits, dim=-1).cpu().item()\n",
    "\n",
    "    trigger_labels, arg_labels = [], []\n",
    "    for i, word_idx in enumerate(word_ids):\n",
    "        if word_idx is not None and word_idx < len(sentence_tokens):\n",
    "            trigger_labels.append(dataset_encoders['trigger'].inverse_transform([trigger_preds[i]])[0])\n",
    "            arg_labels.append(dataset_encoders['arg'].inverse_transform([arg_preds[i]])[0])\n",
    "        elif word_idx is None:\n",
    "            trigger_labels.append('O')\n",
    "            arg_labels.append('O')\n",
    "\n",
    "    if len(trigger_labels) > len(sentence_tokens):\n",
    "        trigger_labels = [label for i, label in enumerate(trigger_labels) if word_ids[i] is not None][:len(sentence_tokens)]\n",
    "        arg_labels = [label for i, label in enumerate(arg_labels) if word_ids[i] is not None][:len(sentence_tokens)]\n",
    "    elif len(trigger_labels) < len(sentence_tokens):\n",
    "        print(f\"Warning: Sentence truncated. Predicted tags length ({len(trigger_labels)}) is less than original tokens length ({len(sentence_tokens)})\")\n",
    "\n",
    "    event_label = dataset_encoders['event'].inverse_transform([event_pred])[0]\n",
    "\n",
    "    return {\n",
    "        'tokens': sentence_tokens,\n",
    "        'trigger_tags': trigger_labels,\n",
    "        'argument_tags': arg_labels,\n",
    "        'event_type': event_label\n",
    "    }\n",
    "\n",
    "model_path = \"best_model.pt\"\n",
    "encoder_dir = \"oneie_encoders\"\n",
    "\n",
    "model = JointModel('xlm-roberta-base', 21, 8, 13)\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "with open(os.path.join(encoder_dir, \"trigger_labels.pkl\"), \"rb\") as f:\n",
    "    trigger_encoder = pickle.load(f)\n",
    "with open(os.path.join(encoder_dir, \"arg_labels.pkl\"), \"rb\") as f:\n",
    "    arg_encoder = pickle.load(f)\n",
    "with open(os.path.join(encoder_dir, \"event_labels.pkl\"), \"rb\") as f:\n",
    "    event_encoder = pickle.load(f)\n",
    "\n",
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "sentence = \"Tiếp tục chương trình Kỳ họp thứ 9, chiều 20/6, Quốc hội họp phiên toàn thể tại Hội trường...\"\n",
    "tokens = sentence.split()\n",
    "\n",
    "result = predict_single_instance(model, tokenizer, tokens,\n",
    "    {'trigger': trigger_encoder, 'arg': arg_encoder, 'event': event_encoder}\n",
    ")\n",
    "\n",
    "print(\"\\n===== PREDICTION =====\")\n",
    "for i in range(len(result['tokens'])):\n",
    "    print(f\"{result['tokens'][i]:<10} Trigger: {result['trigger_tags'][i]:<15} Argument: {result['argument_tags'][i]}\")\n",
    "print(f\"➡️ Event Type: {result['event_type']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
